# Mathematical and Scientific Foundations of AIDM

## Table of Contents
1. [Overview](#overview)
2. [Power System State Estimation](#power-system-state-estimation)
3. [Anomaly Detection Methods](#anomaly-detection-methods)
4. [Attack Models](#attack-models)
5. [Machine Learning Components](#machine-learning-components)
6. [Fusion and Meta-Learning](#fusion-and-meta-learning)
7. [Adversarial Robustness](#adversarial-robustness)
8. [Mathematical Notation](#mathematical-notation)
9. [References](#references)

## Overview

The **Anomaly and Intrusion Detection Model (AIDM)** framework combines multiple mathematical approaches for detecting anomalies and cyber-attacks in power system measurements. This document provides the mathematical foundations and scientific principles underlying each component.

## Power System State Estimation

### Mathematical Model

Power system state estimation is formulated as a weighted least squares problem:

```
minimize J(x) = [z - h(x)]áµ€ Râ»Â¹ [z - h(x)]
```

Where:
- `x âˆˆ â„â¿` is the state vector (voltage magnitudes and phase angles)
- `z âˆˆ â„áµ` is the measurement vector
- `h(x): â„â¿ â†’ â„áµ` is the nonlinear measurement function
- `R âˆˆ â„áµË£áµ` is the measurement error covariance matrix

### Measurement Jacobian

The measurement Jacobian matrix is crucial for FDIA generation:

```
H = âˆ‚h(x)/âˆ‚x |â‚“â‚Œâ‚“Ì‚
```

For power flow measurements:
- **Active power injection**: `Páµ¢ = Váµ¢ Î£â±¼ Vâ±¼ [Gáµ¢â±¼ cos(Î¸áµ¢ - Î¸â±¼) + Báµ¢â±¼ sin(Î¸áµ¢ - Î¸â±¼)]`
- **Reactive power injection**: `Qáµ¢ = Váµ¢ Î£â±¼ Vâ±¼ [Gáµ¢â±¼ sin(Î¸áµ¢ - Î¸â±¼) - Báµ¢â±¼ cos(Î¸áµ¢ - Î¸â±¼)]`
- **Active power flow**: `Páµ¢â±¼ = Váµ¢Â² gáµ¢â±¼ - Váµ¢Vâ±¼ [gáµ¢â±¼ cos(Î¸áµ¢ - Î¸â±¼) + báµ¢â±¼ sin(Î¸áµ¢ - Î¸â±¼)]`

Where:
- `Váµ¢, Î¸áµ¢` are voltage magnitude and phase angle at bus i
- `Gáµ¢â±¼ + jBáµ¢â±¼` are elements of the bus admittance matrix
- `gáµ¢â±¼ + jbáµ¢â±¼` are branch admittance parameters

## Anomaly Detection Methods

### 1. Autoencoder-Based Detection

#### Architecture
The autoencoder consists of an encoder `f: â„áµˆ â†’ â„áµ` and decoder `g: â„áµ â†’ â„áµˆ`:

```
Encoder: h = f(x) = Ïƒ(Wâ‚x + bâ‚)
Decoder: xÌ‚ = g(h) = Ïƒ(Wâ‚‚h + bâ‚‚)
```

#### Loss Function
The reconstruction loss is:

```
L(x, xÌ‚) = ||x - xÌ‚||â‚‚Â² = Î£áµ¢ (xáµ¢ - xÌ‚áµ¢)Â²
```

#### Anomaly Score
For a test sample `x`, the anomaly score is:

```
s(x) = ||x - g(f(x))||â‚‚Â²
```

Anomaly detection: `s(x) > Ï„` where `Ï„` is the threshold determined from training data.

#### Threshold Selection
Using the 95th percentile of reconstruction errors on clean training data:

```
Ï„ = percentileâ‚‰â‚…({s(xáµ¢) : xáµ¢ âˆˆ X_train})
```

### 2. LSTM Forecaster

#### Model Architecture
The LSTM forecaster predicts the next measurement based on historical sequences:

```
hâ‚œ = LSTM(xâ‚œ, hâ‚œâ‚‹â‚)
Å·â‚œâ‚Šâ‚ = Wâ‚’hâ‚œ + bâ‚’
```

#### Prediction Error
The residual-based anomaly score is:

```
r(t) = ||y(t) - Å·(t)||â‚‚Â²
```

#### Temporal Modeling
For a sequence window of length `w`:

```
X_seq = [x(t-w+1), x(t-w+2), ..., x(t)]
y_pred = LSTM(X_seq)
```

### 3. Randomized Transformations

#### Transformation Functions
Multiple randomized transformations `Táµ¢: â„áµˆ â†’ â„áµˆ` are applied:

1. **Gaussian Noise**: `Tâ‚(x) = x + Îµ`, where `Îµ ~ N(0, ÏƒÂ²I)`
2. **Feature Dropout**: `Tâ‚‚(x) = x âŠ™ m`, where `m` is a binary mask
3. **Scaling**: `Tâ‚ƒ(x) = Î±x`, where `Î± ~ U(0.9, 1.1)`
4. **Rotation**: `Tâ‚„(x) = Rx`, where `R` is a random rotation matrix
5. **Permutation**: `Tâ‚…(x) = P(x)`, where `P` is a random permutation

#### Consistency Score
For `n` transformations, the consistency score is:

```
C(x) = (1/n) Î£áµ¢ ||f(x) - f(Táµ¢(x))||â‚‚Â²
```

Where `f` is a feature extraction function (e.g., autoencoder encoder).

## Attack Models

### 1. False Data Injection Attack (FDIA)

#### Mathematical Formulation
An FDIA constructs malicious measurements that bypass bad data detection:

```
z_a = z + a
```

Where the attack vector `a` satisfies:

```
a = Hc
```

For some attack vector `c` on the state variables.

#### Stealth Condition
The attack is undetectable by traditional Ï‡Â² bad data detection if:

```
||z_a - h(xÌ‚_a)||Â²_Râ»Â¹ â‰¤ Ï‡Â²_threshold
```

#### Attack Construction Algorithm
1. Choose target state perturbation `c`
2. Compute attack vector: `a = Hc`
3. Apply physical constraints and rate limiting
4. Generate attacked measurements: `z_a = z + a`

### 2. Temporal Stealth Attack

#### Gradual Ramp Model
The attack evolves gradually over time to avoid detection:

```
a(t) = a(t-1) + Î”a(t)
```

Where `Î”a(t)` is constrained by:

```
||Î”a(t)||âˆ â‰¤ Î´_max
```

#### Temporal Consistency
The attack maintains temporal correlation:

```
Corr(z(t), z(t-1)) â‰ˆ Corr(z_a(t), z_a(t-1))
```

### 3. Replay Attack

#### Data Substitution Model
Replace current measurements with historical data:

```
z_a(t:t+w) = z(s:s+w)
```

Where `s < t` is the source time window.

## Machine Learning Components

### 1. Deep Neural Network Classifier

#### Architecture
Multi-layer perceptron with ReLU activations:

```
hâ‚ = ReLU(Wâ‚x + bâ‚)
hâ‚‚ = ReLU(Wâ‚‚hâ‚ + bâ‚‚)
...
y = sigmoid(Wâ‚—hâ‚—â‚‹â‚ + bâ‚—)
```

#### Loss Function
Binary cross-entropy for anomaly classification:

```
L = -[y log(Å·) + (1-y) log(1-Å·)]
```

### 2. Random Forest

#### Ensemble Prediction
For `T` trees, the prediction is:

```
Å· = (1/T) Î£â‚œ fâ‚œ(x)
```

#### Feature Importance
Gini importance for feature `j`:

```
I(j) = Î£â‚œ Î£â‚™ p(n) * G(n) * I(split_n uses feature j)
```

Where `G(n)` is the Gini impurity at node `n`.

## Fusion and Meta-Learning

### Weighted Fusion

#### Score Combination
Multiple detector scores are combined:

```
s_fusion = Î£áµ¢ wáµ¢ sáµ¢(x)
```

Where `wáµ¢` are learned weights and `sáµ¢(x)` are individual detector scores.

#### Weight Optimization
Weights are optimized to minimize validation error:

```
w* = argmin_w Î£â±¼ L(y_j, Î£áµ¢ wáµ¢ sáµ¢(x_j))
```

### Meta-Classifier Approach

#### Feature Vector Construction
Meta-features from individual detectors:

```
Ï†(x) = [sâ‚(x), sâ‚‚(x), ..., sâ‚–(x), confâ‚(x), ..., confâ‚–(x)]
```

#### Meta-Learning
Train a classifier on meta-features:

```
Å·_meta = f_meta(Ï†(x))
```

## Adversarial Robustness

### 1. Fast Gradient Sign Method (FGSM)

#### Attack Generation
```
x_adv = x + Îµ * sign(âˆ‡â‚“ L(Î¸, x, y))
```

Where:
- `Îµ` is the perturbation magnitude
- `L(Î¸, x, y)` is the loss function
- `âˆ‡â‚“ L` is the gradient with respect to input

### 2. Projected Gradient Descent (PGD)

#### Iterative Attack
```
x_adv^(t+1) = Î _S(x_adv^(t) + Î± * sign(âˆ‡â‚“ L(Î¸, x_adv^(t), y)))
```

Where `Î _S` projects onto the constraint set `S = {x' : ||x' - x||âˆ â‰¤ Îµ}`.

### 3. Adversarial Training

#### Robust Optimization
```
min_Î¸ E_{(x,y)~D} [max_{Î´âˆˆS} L(Î¸, x + Î´, y)]
```

This minimax formulation trains the model to be robust against worst-case perturbations.

## Mathematical Notation

### Sets and Spaces
- `â„`: Real numbers
- `â„â¿`: n-dimensional real vector space
- `â„áµË£â¿`: mÃ—n real matrices
- `ğ’³`: Input space
- `ğ’´`: Output space

### Vectors and Matrices
- `x, y, z`: Vectors (lowercase bold)
- `A, B, H`: Matrices (uppercase bold)
- `xáµ¢`: i-th element of vector x
- `Aáµ¢â±¼`: (i,j)-th element of matrix A
- `xÌ‚`: Estimated/predicted value
- `xÌƒ`: Perturbed/noisy value

### Operations
- `||Â·||â‚‚`: L2 (Euclidean) norm
- `||Â·||âˆ`: Lâˆ (maximum) norm
- `âŠ™`: Element-wise (Hadamard) product
- `âˆ‡`: Gradient operator
- `âˆ‚f/âˆ‚x`: Partial derivative
- `E[Â·]`: Expected value
- `Var[Â·]`: Variance
- `Cov[Â·]`: Covariance

### Probability and Statistics
- `P(Â·)`: Probability
- `p(Â·)`: Probability density function
- `N(Î¼, ÏƒÂ²)`: Normal distribution
- `U(a, b)`: Uniform distribution
- `Ï‡Â²`: Chi-squared distribution

## References

### Power System Security
1. Monticelli, A. (1999). *State Estimation in Electric Power Systems: A Generalized Approach*
2. Liu, Y., Ning, P., & Reiter, M. K. (2011). False data injection attacks against state estimation in electric power grids. *ACM Transactions on Information and System Security*

### Anomaly Detection
3. Chandola, V., Banerjee, A., & Kumar, V. (2009). Anomaly detection: A survey. *ACM Computing Surveys*
4. Goodfellow, I., Bengio, Y., & Courville, A. (2016). *Deep Learning*. MIT Press

### Adversarial Machine Learning
5. Goodfellow, I. J., Shlens, J., & Szegedy, C. (2014). Explaining and harnessing adversarial examples. *arXiv preprint arXiv:1412.6572*
6. Madry, A., et al. (2017). Towards deep learning models resistant to adversarial attacks. *arXiv preprint arXiv:1706.06083*

### Power System Cybersecurity
7. Ten, C. W., Liu, C. C., & Manimaran, G. (2008). Vulnerability assessment of cybersecurity for SCADA systems. *IEEE Transactions on Power Systems*
8. Liang, G., Weller, S. R., Zhao, J., Luo, F., & Dong, Z. Y. (2017). The 2015 Ukraine blackout: Implications for false data injection attacks. *IEEE Transactions on Power Systems*

---

*This document provides the mathematical foundations for understanding and implementing the AIDM framework. For implementation details, refer to the main README.md and source code documentation.*
